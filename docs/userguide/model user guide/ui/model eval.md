---
title: Run a Starwhale Model Evaluation by UI
---

## Create a model evaluation

1 Click **Create** to start configuring a model evaluatioin；

![image](https://github.com/lijing-susan/docs/assets/101299635/6bf68f43-0ec0-406d-bbb7-6e9351457c25)

2 Select the items on the page, and then Click **Submit** to create an evaluation.

[补图]

## Model Evaluation List**

In the evaluation table, you can see all the evaluations of one project in one place.

Each time you run an evaluation with Starwhale Web UI, Starwhale Client or Python SDK, it's added to the top of the table.

![image](https://github.com/lijing-susan/docs/assets/101299635/24087224-c0f2-40db-a565-5a79f2f0db35)

### Side-by-Side Comparison of Evaluations

Select evaluations to compare by clicking the checkbox to include or exclude evaluations.
  
[补动图]
  
### Evaluation Result

 [补动图]

### Evaluation Tasks and Logs
  
**Tasks**

Click **Tasks** tab to see all the tasks of an evaluation, or click a specific bar in the DAG to go to the task table.

![image](https://github.com/lijing-susan/starwhale/assets/101299635/2f580fa4-868e-4d8d-b14a-ea72396fd757)

**Logs**

Click **View logs** button at the end of the task table to view logs.

![image](https://github.com/lijing-susan/starwhale/assets/101299635/f1b896a7-f55b-40c9-a419-f44e0a3575fa)
